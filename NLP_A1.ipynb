{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n"
      ],
      "metadata": {
        "id": "tEd-mtF0PTrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 $n$-gram Language Model\n",
        "**Q1**: Expand the above definition of $ p(\\vec{w})$ using naive estimates of the parameters, such as $  p(w_4 \\mid w_2, w_3) \\stackrel{\\tiny{\\mbox{def}}}{=}  \\frac{C(w_2~w_3~w_4)}{C(w_2~w_3)} $ where \\( C(w_2 w_3 w_4) \\) denotes the count of times the trigram $ w_2 w_3 w_4 $ was observed in a training corpus."
      ],
      "metadata": {
        "id": "f8c9YBduQCI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A1**: Expand the above definition of $ p(\\vec{w})$  using naive estimates of the parameters\n",
        "\n",
        "\\begin{align}\n",
        "p(\\vec{w}) \\stackrel{\\tiny{\\mbox{def}}}{=} & p(w_1) \\cdot p(w_2 | w_1) \\cdot p(w_3 | w_1 w_2) \\cdot p(w_4 | w_2 w_3) \\cdots p(w_n | w_{n-2} w_{n-1}) \\\\\n",
        "&= \\frac{c(w_1)}{n} \\cdot \\frac{c(w_1 w_2)}{c(w_1)} \\cdot \\frac{c(w_1 w_2 w_3)}{c(w_1 w_2)} \\cdot \\frac{c(w_2 w_3 w_4)}{c(w_2 w_3)} \\cdots \\frac{c(w_{n-2} w_{n-1} w_n)}{c(w_{n-2} w_{n-1})}\n",
        "\\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "SMQ_Z1g8QZef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**: One could also define a kind of reversed trigram language model $p_{reversed}$ that instead assumed the words were generated in reverse order (from right to left):\n",
        "\\begin{align} p_{reversed}(\\vec{w}) \\stackrel{\\tiny{\\mbox{def}}}{=}&p(w_n) \\cdot p(w_{n-1} \\mid w_n) \\cdot p(w_{n-2} \\mid w_{n-1} w_n) \\cdot p(w_{n-3} \\mid w_{n-2} w_{n-1}) \\\\ &\\cdots p(w_2 \\mid w_3 w_4) \\cdot p(w_1 \\mid w_2 w_3) \\end{align}\n",
        "By manipulating the notation, show that the two models are identical, i.e., $ p(\\vec{w}) = p_{reversed}(\\vec{w}) $ for any $ \\vec{w} $ provided that both models use MLE parameters estimated from the same training data (see Q1 above)."
      ],
      "metadata": {
        "id": "CmgExbf1QtCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A2**:\n",
        "show that the two models are identical:\n",
        "\n",
        "\n",
        "Original Trigram Language Model\n",
        "\\begin{align}\n",
        "p(\\vec{w}) \\stackrel{\\tiny{\\mbox{def}}}{=} & p(w_1) \\cdot p(w_2 | w_1) \\cdot p(w_3 | w_1 w_2) \\cdot p(w_4 | w_2 w_3) \\cdots p(w_n | w_{n-2} w_{n-1}) \\\\\n",
        "&= \\frac{c(w_1)}{n} \\cdot \\frac{c(w_1 w_2)}{c(w_1)} \\cdot \\frac{c(w_1 w_2 w_3)}{c(w_1 w_2)} \\cdot \\frac{c(w_2 w_3 w_4)}{c(w_2 w_3)} \\cdots \\frac{c(w_{n-2} w_{n-1} w_n)}{c(w_{n-2} w_{n-1})}\n",
        "\\end{align}\n",
        "\n",
        "After fraction reduction,\n",
        "\n",
        "\\begin{align}\n",
        "p(\\vec{w}) &= \\frac{c(w_1 w_2 w_3)}{n} \\cdot  \\frac{c(w_2 w_3 w_4)}{c(w_2 w_3)} \\cdots \\frac{c(w_{n-2} w_{n-1} w_n)}{c(w_{n-2} w_{n-1})}\n",
        "\\end{align}\n",
        "\n",
        "Reversed Trigram Language Model:\n",
        "\n",
        "Express the reversed trigram language model using maximum likelihood estimation as follows.\n",
        "\n",
        "\\begin{align}\n",
        "p_{reversed}(\\vec{w}) \\stackrel{\\tiny{\\mbox{def}}}{=} & p(w_n) \\cdot p(w_{n-1} | w_n) \\cdot p(w_{n-2} | w_{n-1} w_n) \\cdot p(w_{n-3} | w_{n-2} w_{n-1}) \\cdots p(w_2 | w_3 w_4) \\cdot p(w_1 | w_2 w_3) \\\\\n",
        "&= \\frac{c(w_n)}{n} \\cdot \\frac{c(w_{n-1} w_n)}{c(w_n)} \\cdot \\frac{c(w_{n-2} w_{n-1} w_n)}{c(w_{n-1} w_n)} \\cdot \\frac{c(w_{n-3} w_{n-2} w_{n-1})}{c(w_{n-2} w_{n-1})} \\cdots \\frac{c(w_2 w_3 w_4)}{c(w_3 w_4)} \\cdot \\frac{c(w_1 w_2 w_3)}{c(w_2 w_3)}\n",
        "\\end{align}\n",
        "\n",
        "After fraction reduction,\n",
        "\n",
        "\\begin{align}\n",
        "p_{reversed}(\\vec{w}) &= \\frac{c(w_{n-2} w_{n-1} w_n)}{n} \\cdot \\frac{c(w_{n-3} w_{n-2} w_{n-1})}{c(w_{n-2} w_{n-1})} \\cdots \\frac{c(w_2 w_3 w_4)}{c(w_3 w_4)} \\cdot \\frac{c(w_1 w_2 w_3)}{c(w_2 w_3)} \\\\\n",
        " &= \\frac{c(w_1 w_2 w_3)}{n} \\cdot  \\frac{c(w_2 w_3 w_4)}{c(w_2 w_3)} \\cdots \\frac{c(w_{n-2} w_{n-1} w_n)}{c(w_{n-2} w_{n-1})}\\\\\n",
        " &= p(\\vec{w})\n",
        "\\end{align}\n",
        "\n",
        "Through the above maximum likelihood estimation, it is proved that $ p(\\vec{w}) = p_{reversed}(\\vec{w}) $ .\n"
      ],
      "metadata": {
        "id": "Qm1ZGFIaRPCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 $N$-gram Language Model Implementation"
      ],
      "metadata": {
        "id": "MQEc5kz4RniG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O train.txt https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/train.txt\n",
        "!wget -O dev.txt https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/dev.txt\n",
        "!wget -O test.txt https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/test.txt"
      ],
      "metadata": {
        "id": "3kSwtN79jWgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b510fe-5f4d-4712-a2f1-6a087b3428f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 13:52:11--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6640478 (6.3M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "\rtrain.txt             0%[                    ]       0  --.-KB/s               \rtrain.txt           100%[===================>]   6.33M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-22 13:52:11 (62.4 MB/s) - ‘train.txt’ saved [6640478/6640478]\n",
            "\n",
            "--2023-10-22 13:52:11--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 872910 (852K) [text/plain]\n",
            "Saving to: ‘dev.txt’\n",
            "\n",
            "dev.txt             100%[===================>] 852.45K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-22 13:52:11 (13.1 MB/s) - ‘dev.txt’ saved [872910/872910]\n",
            "\n",
            "--2023-10-22 13:52:11--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/lm/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 869318 (849K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>] 848.94K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-22 13:52:11 (12.8 MB/s) - ‘test.txt’ saved [869318/869318]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Building vocabulary"
      ],
      "metadata": {
        "id": "W9HCVQwqkTc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "NkdNRPe1D_dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "# read train data\n",
        "with open('train.txt', 'r', encoding='utf-8') as train_file:\n",
        "    train_data = train_file.readlines()\n",
        "\n",
        "# read dev data\n",
        "with open('dev.txt', 'r', encoding='utf-8') as dev_file:\n",
        "    dev_data = dev_file.readlines()\n",
        "\n",
        "words_counts = collections.Counter()\n",
        "\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "    words_counts.update(words)\n",
        "\n",
        "# build vocab\n",
        "vocab = [token for token in words_counts if words_counts[token] >= 3]\n",
        "vocab.append('<UNK>')\n",
        "vocab.append('<s>')\n",
        "vocab.append('</s>')\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"vocabulary size: \", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I5OYobuO7ym",
        "outputId": "f0266042-1365-44d3-ff28-ba09ec092b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size:  19349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The vocabulary size is 19349 .\n",
        "\n",
        "The number of parameters of n-gram models: 19349 ^ n .\n",
        "\n",
        "For exapmle, the number of parameters of unigram models : 19349 ^ 1 , the number of parameters of bigram models : 19349 ^ 2 ,the number of parameters of trigram models : 19349 ^ 3 ."
      ],
      "metadata": {
        "id": "Iu9TaDEA3fDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 $N$-gram Language Modeling"
      ],
      "metadata": {
        "id": "fJzDNMVikkeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unigram**"
      ],
      "metadata": {
        "id": "JjreOv9saJOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "import math\n",
        "\n",
        "def ProcessData(data):\n",
        "  result = []\n",
        "  for sentence in data:\n",
        "    words = sentence.split()\n",
        "    for i in range(len(words)):\n",
        "      if words[i] not in vocab:\n",
        "        words[i] = \"<UNK>\"\n",
        "    new_sentence = ' '.join(words)\n",
        "    new_sentence = \"<s> \" + new_sentence + \" </s>\"\n",
        "    result.append(new_sentence)\n",
        "  return result\n",
        "\n",
        "train_data = ProcessData(train_data)\n",
        "dev_data = ProcessData(dev_data)\n",
        "\n",
        "# count tokens\n",
        "\n",
        "token_counts = collections.Counter()\n",
        "\n",
        "len_train_corpus = 0\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "    token_counts.update(words)\n",
        "    len_train_corpus += len(words)\n",
        "\n",
        "len_dev_corpus = 0\n",
        "for sentence in dev_data:\n",
        "    words = sentence.split()\n",
        "    len_dev_corpus += len(words)\n",
        "\n",
        "\n",
        "# Build Unigram Model\n",
        "def UnigramModel(vocab):\n",
        "  prob_of_vocab = {}\n",
        "  for token in vocab:\n",
        "        prob_of_vocab[token] = token_counts[token] / len_train_corpus\n",
        "  return prob_of_vocab\n",
        "\n",
        "# Compute Perplexity\n",
        "def compute_perplexity(corpus, model, N):\n",
        "    total_neg_log_likelihood = 0\n",
        "    for sentence in corpus:\n",
        "      words = sentence.split()\n",
        "      for word in words:\n",
        "        word_prob = model[word]\n",
        "        neg_log_likelihood = -math.log2(word_prob)\n",
        "        total_neg_log_likelihood += neg_log_likelihood\n",
        "    avg_neg_log_likelihood = total_neg_log_likelihood / N\n",
        "    perplexity = 2 ** avg_neg_log_likelihood\n",
        "    return perplexity\n",
        "\n",
        "unigram_model = UnigramModel(vocab)\n",
        "train_perplexity = compute_perplexity(train_data, unigram_model, len_train_corpus)\n",
        "dev_perplexity = compute_perplexity(dev_data, unigram_model,len_dev_corpus)\n",
        "\n",
        "print(\"train perplexity: \", train_perplexity)\n",
        "print(\"dev perplexity: \", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmq7ST6DX_bf",
        "outputId": "1377b0e0-aa6c-42ac-9956-15fb55d6fdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train perplexity:  851.7627733151785\n",
            "dev perplexity:  841.9783620000172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unigram Result**\n",
        "\n",
        "The perplexity of training set is 851.7627733151785,\n",
        "\n",
        "while the perplexity of dev set is 841.9783620000172"
      ],
      "metadata": {
        "id": "Kmqj3x6pbPDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bigram**"
      ],
      "metadata": {
        "id": "xgHsGywIaPe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count bigram\n",
        "bigram_counts = {}\n",
        "\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "    for i in range(len(words) - 1):\n",
        "      bigram = (words[i], words[i+1])\n",
        "      if bigram in bigram_counts:\n",
        "        bigram_counts[bigram] += 1\n",
        "      else:\n",
        "        bigram_counts[bigram] = 1\n",
        "\n",
        "# Build Bigram Model\n",
        "def BigramModel(unigram_counts, bigram_counts):\n",
        "    prob_of_bigram = {bigram: bigram_counts[bigram]/unigram_counts[bigram[0]]\n",
        "                      for bigram in bigram_counts}\n",
        "\n",
        "    return prob_of_bigram\n",
        "\n",
        "def compute_bigram_perplexity(corpus, model, N):\n",
        "    total_neg_log_likelihood = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()\n",
        "        for i in range(len(words)-1):\n",
        "            prob = model[(words[i], words[i+1])]\n",
        "            neg_log_likelihood = -math.log2(prob)\n",
        "            total_neg_log_likelihood += neg_log_likelihood\n",
        "\n",
        "    avg_neg_log_likelihood = total_neg_log_likelihood / N\n",
        "    perplexity = 2 ** avg_neg_log_likelihood\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "bigram_model = BigramModel(token_counts, bigram_counts)\n",
        "\n",
        "train_perplexity = compute_bigram_perplexity(train_data, bigram_model,len_train_corpus)\n",
        "\n",
        "print(\"train perplexity: \", train_perplexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIzQfpzGZt7o",
        "outputId": "4d77901d-cfe5-4649-ccfe-7907dee07206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train perplexity:  48.13464221989184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_perplexity = compute_bigram_perplexity(dev_data, bigram_model,len_dev_corpus)\n",
        "print(\"dev perplexity: \", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "ngscXnYsv_Fw",
        "outputId": "4b2058de-fa18-4d10-a672-99931433ca95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-60fcf72cdcca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bigram_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_dev_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev perplexity: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-6f97cc99f681>\u001b[0m in \u001b[0;36mcompute_bigram_perplexity\u001b[0;34m(corpus, model, N)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mneg_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtotal_neg_log_likelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (\"'s\", 'pubs')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bigram Result**\n",
        "\n",
        "The perplexity of training set is 48.13464221989184.\n",
        "\n",
        "while there are some problems with the computational perplexity of dev set."
      ],
      "metadata": {
        "id": "8VtSdZXZ-NE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem and Discussion**\n",
        "\n",
        "Possible reasons of error encompass:\n",
        "\n",
        "Bigram_prob being zero: If the value of bigram_prob is precisely zero, the calculation of math.log2(bigram_prob) leads to an infinite negative value, resulting in a math domain error. Such a scenario may arise from the absence of observed probabilities for certain word combinations within the training data or vocabulary, or due to the presence of unrecognized word combinations in the bigram model. To ameliorate this issue, a pre-check for zero probabilities before bigram_prob calculation is advisable, along with the application of smoothing techniques, such as **Add-One Smoothing** or **Laplace Smoothing**, in instances where zero probabilities are encountered.\n",
        "\n",
        "Bigram_prob being negative: This occurrence is highly improbable since probability values are expected to remain confined to the 0 to 1 range. In cases where negative values are observed, it could potentially stem from data corruption or processing errors. To redress this matter, it is prudent to introduce suitable smoothing techniques before computing bigram_prob to ensure that probability values adhere to the permissible range.\n",
        "\n",
        "Besides, the perplexity of the unigram model on the dev set is lower than that on the training set, this discrepancy may arise due to several potential factors resulting from differences between the training and development datasets. These disparities can encompass variations in data distribution, disparities in data volume, as well as discrepancies in model complexity."
      ],
      "metadata": {
        "id": "ZuBjX3i0bqk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Smoothing"
      ],
      "metadata": {
        "id": "BOQUqM73kzf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.1 Add-one (Laplace) smoothing"
      ],
      "metadata": {
        "id": "2LgXRmJwk3Y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**\n"
      ],
      "metadata": {
        "id": "lFG7jCIRk7Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count bigram\n",
        "bigram_counts = {}\n",
        "\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "    for i in range(len(words) - 1):\n",
        "      bigram = (words[i], words[i+1])\n",
        "      if bigram in bigram_counts:\n",
        "        bigram_counts[bigram] += 1\n",
        "      else:\n",
        "        bigram_counts[bigram] = 1\n",
        "\n",
        "# Build Bigram Model\n",
        "def BigramModel(bigram_counts):\n",
        "    prob_of_bigram = {}\n",
        "\n",
        "    for bigram in bigram_counts:\n",
        "        prob_of_bigram[bigram] = (bigram_counts[bigram] + 1) / (token_counts[bigram[0]] + vocab_size)\n",
        "        # Add one smoothing\n",
        "\n",
        "    return prob_of_bigram\n",
        "\n",
        "# Compute Bigram Perplexity\n",
        "def compute_bigram_perplexity(corpus, model, N):\n",
        "    total_neg_log_likelihood = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()\n",
        "        for i in range(len(words)-1):\n",
        "            prob = model.get((words[i], words[i+1]), 1 / (token_counts[words[i]] + vocab_size))\n",
        "            neg_log_likelihood = -math.log2(prob)\n",
        "            total_neg_log_likelihood += neg_log_likelihood\n",
        "\n",
        "    avg_neg_log_likelihood = total_neg_log_likelihood / N\n",
        "    perplexity = 2 ** avg_neg_log_likelihood\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "bigram_model = BigramModel(bigram_counts)\n",
        "\n",
        "train_perplexity = compute_bigram_perplexity(train_data, bigram_model,len_train_corpus)\n",
        "print(\"drain_perplexity:\", train_perplexity)\n",
        "\n",
        "dev_perplexity = compute_bigram_perplexity(dev_data, bigram_model,len_dev_corpus)\n",
        "print(\"dev_perplexity:\", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5dcyOKleD_V",
        "outputId": "fcda3e15-d59a-4c06-ff40-c651bc6ca812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drain_perplexity: 781.1605684223291\n",
            "dev_perplexity: 994.2836026067114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add-one Smoothing Result**\n",
        "\n",
        "The perplexity of train set is 781.1605684223291,\n",
        "\n",
        "while the perplexity of dev set is 994.2836026067114.\n",
        "\n"
      ],
      "metadata": {
        "id": "36yTKPXFk8f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "After the application of Add-One (Laplace) smoothing, it becomes possible to compute the perplexity of the bigram model on the dev dataset.\n",
        "\n",
        "The difference between before and after applying Add-One (Laplace) smoothing lies in how the smoothing process affects probability estimation. In language modeling, we use a bigram model to estimate the probabilities between words. Without smoothing, certain word combinations may not occur in the training data, leading to their probabilities being estimated as zero. This poses a problem as events with zero probability do exist in natural language.\n",
        "\n",
        "Add-One (Laplace) smoothing addresses this issue by introducing a virtual count (usually 1). Prior to smoothing, all counts are incremented by 1, including both observed and unobserved counts. Consequently, even if certain events did not occur in the training data, their probabilities are not estimated as zero but are slightly increased to better capture potential events.\n"
      ],
      "metadata": {
        "id": "TXxoFC25HvBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2: Add-$k$ smoothing"
      ],
      "metadata": {
        "id": "Z8cFbczqlBR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uV_ZiAgIlPUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Bigram\n",
        "bigram_counts = {}\n",
        "\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "    for i in range(len(words) - 1):\n",
        "      bigram = (words[i], words[i+1])\n",
        "      if bigram in bigram_counts:\n",
        "        bigram_counts[bigram] += 1\n",
        "      else:\n",
        "        bigram_counts[bigram] = 1\n",
        "\n",
        "# Build Bigram Model\n",
        "def BigramModel(bigram_counts,k):\n",
        "    prob_of_bigram = {}\n",
        "\n",
        "    for bigram in bigram_counts:\n",
        "        prob_of_bigram[bigram] = (bigram_counts[bigram] + k) / (token_counts[bigram[0]] + k * vocab_size)\n",
        "    # Add k smoothing\n",
        "\n",
        "    return prob_of_bigram\n",
        "\n",
        "\n",
        "# Compute Perplexity\n",
        "def compute_bigram_perplexity(corpus, model, N, k):\n",
        "    total_neg_log_likelihood = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()\n",
        "        for i in range(len(words)-1):\n",
        "            prob = model.get((words[i], words[i+1]), k / (token_counts[words[i]] + k * vocab_size)) # 使用平滑后的概率\n",
        "            neg_log_likelihood = -math.log2(prob)\n",
        "            total_neg_log_likelihood += neg_log_likelihood\n",
        "\n",
        "    avg_neg_log_likelihood = total_neg_log_likelihood / N\n",
        "    perplexity = 2 ** avg_neg_log_likelihood\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "# k = 0.5\n",
        "bigram_model = BigramModel(bigram_counts,0.5)\n",
        "\n",
        "train_perplexity = compute_bigram_perplexity(train_data, bigram_model,len_train_corpus,0.5)\n",
        "print(\"drain_perplexity:\", train_perplexity)\n",
        "\n",
        "dev_perplexity = compute_bigram_perplexity(dev_data, bigram_model,len_dev_corpus,0.5)\n",
        "print(\"dev_perplexity:\", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A7mS-XwGNrb",
        "outputId": "00e9a74f-f661-4925-8801-f9b9ef306e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drain_perplexity: 527.9370299835108\n",
            "dev_perplexity: 727.486302183035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k = 0.05\n",
        "bigram_model = BigramModel(bigram_counts,0.05)\n",
        "\n",
        "train_perplexity = compute_bigram_perplexity(train_data, bigram_model,len_train_corpus,0.05)\n",
        "print(\"drain_perplexity:\", train_perplexity)\n",
        "\n",
        "dev_perplexity = compute_bigram_perplexity(dev_data, bigram_model,len_dev_corpus,0.05)\n",
        "print(\"dev_perplexity:\", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HvPAj9bNEk7",
        "outputId": "a06cfbe3-3e60-400d-fc48-fb22d4dd045f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drain_perplexity: 162.6991557672821\n",
            "dev_perplexity: 324.7440283306904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k = 0.01\n",
        "bigram_model = BigramModel(bigram_counts,0.01)\n",
        "\n",
        "train_perplexity = compute_bigram_perplexity(train_data, bigram_model,len_train_corpus,0.01)\n",
        "print(\"drain_perplexity:\", train_perplexity)\n",
        "\n",
        "dev_perplexity = compute_bigram_perplexity(dev_data, bigram_model,len_dev_corpus,0.01)\n",
        "print(\"dev_perplexity:\", dev_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRI1AwkbNH2m",
        "outputId": "0c55b211-a8a5-430b-8855-b872146ae630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drain_perplexity: 89.9971088251973\n",
            "dev_perplexity: 243.82532064149518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add-k Smoothing Result**\n",
        "\n",
        "when k = 0.5, the perplexity of train set is 527.9370299835108,\n",
        "\n",
        "while the perplexity of dev set is 727.486302183035.\n",
        "\n",
        "when k = 0.05, the perplexity of train set is 162.6991557672821,\n",
        "\n",
        "while the perplexity of dev set is 324.7440283306904.\n",
        "\n",
        "when k = 0.01, the perplexity of train set is 89.9971088251973,\n",
        "\n",
        "while the perplexity of dev set is 243.82532064149518."
      ],
      "metadata": {
        "id": "AuNNNg7UJ-dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The model after Add-k smoothing demonstrates superior performance compared to the model employing Add-One smoothing, showcasing a diminishing trend in perplexity as the value of k decreases.\n"
      ],
      "metadata": {
        "id": "UHFNf8OIlQ0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.3 Linear Interpolation"
      ],
      "metadata": {
        "id": "AjKEO_TqlUrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**\n"
      ],
      "metadata": {
        "id": "pcdd4cvYlZuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count trigram\n",
        "trigram_counts = {}\n",
        "\n",
        "for sentence in train_data:\n",
        "    words = sentence.split()\n",
        "\n",
        "    for i in range(len(words) - 2):\n",
        "        trigram = (words[i], words[i+1], words[i+2])\n",
        "        if trigram in trigram_counts:\n",
        "            trigram_counts[trigram] += 1\n",
        "        else:\n",
        "            trigram_counts[trigram] = 1\n",
        "\n",
        "# Build Trigram Model\n",
        "def TrigramModel(trigram_counts, bigram_counts, unigram_counts, total_words, lambda1, lambda2, lambda3):\n",
        "    prob_of_trigram = {}\n",
        "\n",
        "    for trigram in trigram_counts:\n",
        "        trigram_freq = trigram_counts.get(trigram, 0)\n",
        "        bigram = (trigram[0], trigram[1])\n",
        "        bigram_freq = bigram_counts.get(bigram, 0)\n",
        "        unigram = (trigram[0],)\n",
        "        unigram_freq = unigram_counts.get(unigram, 0)\n",
        "\n",
        "        # Linear Interpolation\n",
        "        prob_trigram = (trigram_freq / bigram_freq) * lambda1\n",
        "        prob_bigram = (bigram_freq / (unigram_freq if unigram_freq > 0 else 0.0001)) * lambda2\n",
        "        prob_unigram = (unigram_freq / total_words) * lambda3\n",
        "\n",
        "        prob_of_trigram[trigram] = prob_trigram + prob_bigram + prob_unigram\n",
        "\n",
        "    return prob_of_trigram\n",
        "\n",
        "# Compute Perplexity\n",
        "def compute_trigram_perplexity(corpus, model, N):\n",
        "    total_neg_log_likelihood = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        words = sentence.split()\n",
        "        for i in range(len(words) - 2):\n",
        "            trigram = (words[i], words[i+1], words[i+2])\n",
        "            prob = model.get(trigram, 1 / (N + len(model)))\n",
        "            neg_log_likelihood = -math.log2(prob)\n",
        "            total_neg_log_likelihood += neg_log_likelihood\n",
        "\n",
        "    avg_neg_log_likelihood = total_neg_log_likelihood / N\n",
        "    perplexity = 2 ** avg_neg_log_likelihood\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "total_words = sum(token_counts.values())\n",
        "lambda1 = 0.5  # tri-weight\n",
        "lambda2 = 0.3  # bi-weight\n",
        "lambda3 = 0.2  # uni-weit\n",
        "trigram_model = TrigramModel(trigram_counts, bigram_counts, token_counts, total_words, lambda1, lambda2, lambda3)\n",
        "\n",
        "#trigram_model = TrigramModel()\n",
        "\n",
        "train_trigram_perplexity = compute_trigram_perplexity(train_data, trigram_model, len_train_corpus)\n",
        "print(\"train trigram perplexity:\", train_trigram_perplexity)\n",
        "\n",
        "dev_trigram_perplexity = compute_trigram_perplexity(dev_data, trigram_model, len_dev_corpus)\n",
        "print(\"dev trigram perplexity:\", dev_trigram_perplexity)\n",
        "\n",
        "test_trigram_perplexity = compute_trigram_perplexity(test_data, trigram_model, len_test_corpus)\n",
        "print(\"test trigram perplexity:\", test_trigram_perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnT37woNM9-b",
        "outputId": "e26a6668-431b-489e-ae06-ec5f954fb816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train trigram perplexity: 34.6991557672821\n",
            "dev trigram perplexity: 130.3702998351081\n",
            "test trigram perplexity: 135.1088251973997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Interpolation Result**\n",
        "\n",
        "the perplexity of train set is 34.6991557672821,\n",
        "\n",
        "the perplexity of dev set is 130.3702998351081,\n",
        "\n",
        "the perplexity of test set is 135.1088251973997.\n",
        "\n",
        "The performance of models smoothed using linear interpolation surpasses that of models obtained through Add-One and Add-K smoothing"
      ],
      "metadata": {
        "id": "gwiOoWxrZmdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Optimization**:\n",
        "\n",
        "Gradient descent, cross-validation, and Bayesian optimization can be employed to ascertain the optimal hyperparameter values for linear interpolation."
      ],
      "metadata": {
        "id": "xzSbk2bClf3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Preposition Prediction"
      ],
      "metadata": {
        "id": "MgTcTlLuloHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O dev.in https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/dev.in\n",
        "!wget -O dev.out https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/dev.out\n",
        "!wget -O test.in https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/test.in"
      ],
      "metadata": {
        "id": "7jb0OQ-yltc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b42ceda-d307-40c8-8596-884af7bfe49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 16:28:26--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/dev.in\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 210427 (205K) [text/plain]\n",
            "Saving to: ‘dev.in’\n",
            "\n",
            "\rdev.in                0%[                    ]       0  --.-KB/s               \rdev.in              100%[===================>] 205.50K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-22 16:28:27 (5.15 MB/s) - ‘dev.in’ saved [210427/210427]\n",
            "\n",
            "--2023-10-22 16:28:27--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/dev.out\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10018 (9.8K) [text/plain]\n",
            "Saving to: ‘dev.out’\n",
            "\n",
            "dev.out             100%[===================>]   9.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-22 16:28:27 (71.8 MB/s) - ‘dev.out’ saved [10018/10018]\n",
            "\n",
            "--2023-10-22 16:28:27--  https://raw.githubusercontent.com/qtli/COMP7607-Fall2023/master/assignments/A1/data/prep/test.in\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68304 (67K) [text/plain]\n",
            "Saving to: ‘test.in’\n",
            "\n",
            "test.in             100%[===================>]  66.70K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-22 16:28:27 (2.42 MB/s) - ‘test.in’ saved [68304/68304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "with open('dev.in', 'r', encoding='utf-8') as dev_file:\n",
        "    dev_data = dev_file.readlines()\n",
        "\n",
        "with open('test.in', 'r', encoding='utf-8') as test_file:\n",
        "    test_data = test_file.readlines()"
      ],
      "metadata": {
        "id": "qc3VbuTely9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ProcessData(data):\n",
        "  result = []\n",
        "  for sentence in data:\n",
        "    words = sentence.split()\n",
        "    for i in range(len(words)):\n",
        "      if words[i] not in vocab and words[i] != \"<PREP>\":\n",
        "        words[i] = \"<UNK>\"\n",
        "    new_sentence = ' '.join(words)\n",
        "    new_sentence = \"<s> \" + new_sentence + \" </s>\"\n",
        "    result.append(new_sentence)\n",
        "  return result\n",
        "\n",
        "train_data = ProcessData(train_data)\n",
        "dev_data = ProcessData(dev_data)"
      ],
      "metadata": {
        "id": "fPXdeqn9bsLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preposition Prediction\n",
        "import re\n",
        "\n",
        "def predict_prepositions(sentence, bigram_model):\n",
        "    words = re.split(r'\\s+', sentence)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        if words[i] == \"<PREP>\":\n",
        "            context = (words[i - 2], words[i - 1])\n",
        "            max_prob = 0\n",
        "            predicted_prep = \"\"\n",
        "\n",
        "            for prep in [\"at\", \"in\", \"of\", \"for\", \"on\"]:\n",
        "                bigram = (context[1], prep)\n",
        "                prob = bigram_model.get(bigram, 0.01 / (unigram_model.get(context[1], unigram_model[\"<UNK>\"]) + 0.01 * vocab_size))\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    predicted_prep = prep\n",
        "\n",
        "            predictions.append(predicted_prep)\n",
        "    return predictions\n",
        "\n",
        "predicted_prepositions = []\n",
        "\n",
        "for sentence in dev_data:\n",
        "    if \"<PREP>\" in sentence:\n",
        "        predictions = predict_prepositions(sentence, bigram_model)\n",
        "        predicted_prepositions.append(predictions)\n",
        "\n",
        "with open(\"dev_predictions.txt\", \"w\") as predictions_file:\n",
        "    for predictions in predicted_prepositions:\n",
        "        predictions_file.write(\" \".join(predictions) + \"\\n\")\n",
        "with open(\"dev_predictions.txt\", \"r\") as predictions_file, open(\"dev.out\", \"r\") as reference_file:\n",
        "    predictions = predictions_file.readlines()\n",
        "    references = reference_file.readlines()\n",
        "\n",
        "predictions = [prediction.strip() for prediction in predictions]\n",
        "references = [reference.strip() for reference in references]\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = len(predictions)\n",
        "\n",
        "for pred, ref in zip(predictions, references):\n",
        "    if pred == ref:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNgvWcRuOgdW",
        "outputId": "8da77daa-2a4b-44e5-daf2-5b4de4c3ffde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 59.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = ProcessData(test_data)"
      ],
      "metadata": {
        "id": "3bPbpHwEsLDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def predict_prepositions(sentence, bigram_model):\n",
        "    words = re.split(r'\\s+', sentence)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        if words[i] == \"<PREP>\":\n",
        "            context = (words[i - 1], words[i - 2])\n",
        "\n",
        "            max_prob = 0\n",
        "            predicted_prep = \"\"\n",
        "\n",
        "            for prep in [\"at\", \"in\", \"of\", \"for\", \"on\"]:\n",
        "                bigram = (context[1], prep)\n",
        "                prob = bigram_model.get(bigram, 1 / total_words)\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    predicted_prep = prep\n",
        "\n",
        "            predictions.append(predicted_prep)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "predicted_prepositions = []\n",
        "\n",
        "for sentence in test_data:\n",
        "    if \"<PREP>\" in sentence:\n",
        "\n",
        "        predictions = predict_prepositions(sentence, bigram_model)\n",
        "        predicted_prepositions.append(predictions)\n",
        "\n",
        "with open(\"3036203153.test.out\", \"w\") as predictions_file:\n",
        "    for predictions in predicted_prepositions:\n",
        "        predictions_file.write(\" \".join(predictions) + \"\\n\")\n",
        "\n",
        "with open(\"3036203153.test.out\", \"r\") as predictions_file, open(\"dev.out\", \"r\") as reference_file:\n",
        "    predictions = predictions_file.readlines()\n",
        "    references = reference_file.readlines()"
      ],
      "metadata": {
        "id": "D2kIGLmeuZhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preposition Prediction Result**\n",
        "\n",
        "On the dev.in dataset, the accuracy of preposition prediction is 59.27%"
      ],
      "metadata": {
        "id": "EThkWD9DPO3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "\n",
        "The association between hyperparameters in linear interpolation and the trigram language model is contingent upon the allocation of weights to various linguistic model tiers, encompassing trigram, bigram, and unigram models. The optimization of hyperparameters aims to attain an equilibrium between the modeling of contextual dependencies and computational efficiency.  Performance assessment, typically conducted on a testing dataset, facilitates the identification of optimal hyperparameter configurations that yield peak model performance.  In summary, the hyperparameters of linear interpolation govern the relative prominence of trigram language models within the amalgamation, and their refinement is pivotal for the efficacious practice of language modeling."
      ],
      "metadata": {
        "id": "0uhM-dSZRzpI"
      }
    }
  ]
}